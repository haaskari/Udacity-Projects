import csv
import cv2
#import utils
import argparse
import numpy as np
from sklearn.model_selection import train_test_split
import cv2
import numpy as np
from nn import model
from sklearn.utils import shuffle
from keras.models import Sequential
from keras.layers import Flatten, Dense, Lambda, Conv2D, Dropout

data = []
#model = model
epochs = 2
training_samples = []
validation_samples = []
correction_factor = 0.2
base_path = './data/data/'
image_path = base_path + '/IMG/'
driving_log_path = base_path + '/driving_log.csv'


def bgr2rgb(image):
    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

def flipimg(image):
    return cv2.flip(image, 1)

def cropimg(image):
    cropped = image[60:130, :]
    return cropped

def resize(image, shape=(160, 70)):
    return cv2.resize(image, shape)

def crop_and_resize(image):
    cropped = cropimg(image)
    resized = resize(cropped)
    return resized

def import_data():
    with open(driving_log_path) as csvfile:
        reader = csv.reader(csvfile)
            # Skip the column names row
        next(reader)

        for line in reader:
            data.append(line)
    return None

import_data()

def process_batch(batch_sample):
    steering_angle = np.float32(batch_sample[3])
    images, steering_angles = [], []

    for image_path_index in range(3):
        image_name = batch_sample[image_path_index].split('/')[-1]

        image = cv2.imread(image_path + image_name)
        rgb_image = bgr2rgb(image)
        resized = crop_and_resize(rgb_image)

        images.append(resized)

        if image_path_index == 1:
            steering_angles.append(steering_angle + correction_factor)
        elif image_path_index == 2:
            steering_angles.append(steering_angle - correction_factor)
        else:
            steering_angles.append(steering_angle)

        if image_path_index == 0:
            flipped_center_image = flipimg(resized)
            images.append(flipped_center_image)
            steering_angles.append(-steering_angle)

    return images, steering_angles

def data_generator(samples, batch_size=128):
    num_samples = len(samples)

    while True:
        shuffle(samples)

        for offset in range(0, num_samples, batch_size):
            batch_samples = samples[offset:offset + batch_size]
            images, steering_angles = [], []

            for batch_sample in batch_samples:
                augmented_images, augmented_angles = process_batch(batch_sample)
                images.extend(augmented_images)
                steering_angles.extend(augmented_angles)

            X_train, y_train = np.array(images), np.array(steering_angles)
            yield shuffle(X_train, y_train)

def split_data():
    train, validation = train_test_split(data, test_size=0.2)
    training_samples, validation_samples = train, validation
    print ('training_samples ',len(training_samples))
    print ('validation_samples ',len(validation_samples))
    return None

def train_generator(batch_size=128):
    return data_generator(samples=training_samples, batch_size=batch_size)

def validation_generator(batch_size=128):
    return data_generator(samples=validation_samples, batch_size=batch_size)

train, validation = train_test_split(data, test_size=0.2)
training_samples, validation_samples = train, validation

model = Sequential()
model.add(Lambda(lambda x:  (x / 127.5) - 1., input_shape=(70, 160, 3)))
model.add(Conv2D(filters=24, kernel_size=5, strides=(2, 2), activation='relu'))
model.add(Conv2D(filters=36, kernel_size=5, strides=(2, 2), activation='relu'))
model.add(Conv2D(filters=48, kernel_size=5, strides=(2, 2), activation='relu'))
model.add(Conv2D(filters=64, kernel_size=3, strides=(1, 1), activation='relu'))
model.add(Conv2D(filters=64, kernel_size=3, strides=(1, 1), activation='relu'))

model.add(Flatten())
model.add(Dense(100, activation='relu'))
model.add(Dense(50, activation='relu'))
model.add(Dense(10, activation='relu'))
model.add(Dense(1))
model.compile(loss='mse', optimizer='adam')



model.fit_generator(generator=train_generator(),
                    validation_data=validation_generator(),
                    epochs=epochs,
                    steps_per_epoch=len(training_samples) * 2,
                    validation_steps=len(validation_samples))
model.save('model.h5')